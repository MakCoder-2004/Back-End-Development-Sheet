# Node.js Streams: A Comprehensive Guide

This guide covers key concepts, practical issues, and implementations related to Node.js streams, based on a structured learning path.

---

## Benchmarking Writing a Million Times to a File

Learn how to measure performance using `fs.writeFileSync` vs. streams:

```js
const fs = require('fs');
console.time('write');

for (let i = 0; i < 1_000_000; i++) {
  fs.appendFileSync('output.txt', `Line ${i}\n`);
}

console.timeEnd('write');
```

## Using Streams Naively in Our Solution

Basic usage of writable streams without error handling:

```js
const fs = require('fs');
const stream = fs.createWriteStream('stream_output.txt');

for (let i = 0; i < 1000000; i++) {
  stream.write(`Line ${i}\n`);
}

stream.end();
```

## So What Exactly Are Streams?

Streams are objects that let you read data from a source or write data to a destination in a continuous fashion.

* **Types**: Readable, Writable, Duplex, Transform

## Understanding Different Types of Streams

### Types:

* **Readable**: `fs.createReadStream()`
* **Writable**: `fs.createWriteStream()`
* **Duplex**: Both readable and writable (e.g., TCP sockets)
* **Transform**: Modifies data as it is written and read (e.g., compression)

## Fixing the Memory Issue in Our Program

Using backpressure to avoid memory overflow:

```js
const stream = fs.createWriteStream('safe_output.txt');

function writeMillion() {
  let i = 1000000;
  function write() {
    let ok = true;
    while (i > 0 && ok) {
      ok = stream.write(`Line ${i}\n`);
      i--;
    }
    if (i > 0) stream.once('drain', write);
  }
  write();
}

writeMillion();
```

## Reading Writable Streams Node.js Docs and Recap

Refer to [Node.js Docs - Stream](https://nodejs.org/api/stream.html) for complete APIs.

## Readable Streams in Action

```js
const fs = require('fs');
const readStream = fs.createReadStream('input.txt', 'utf8');

readStream.on('data', chunk => {
  console.log(chunk);
});
```

## Selectively Writing Our Data from the Readable Stream

Example: Filter lines before writing:

```js
const readline = require('readline');
const fs = require('fs');

const readStream = fs.createReadStream('input.txt');
const writeStream = fs.createWriteStream('filtered.txt');
const rl = readline.createInterface({ input: readStream });

rl.on('line', line => {
  if (line.includes('error')) writeStream.write(line + '\n');
});
```

## Understanding the Splitting Issue

Problem: Chunks of data may split words/lines in streaming data.
Solution: Use buffers and delimiters smartly.

## Implementing the Solution and Resolving the Splitting Issue

```js
let leftover = '';
readStream.on('data', chunk => {
  const lines = (leftover + chunk).split('\n');
  leftover = lines.pop();
  lines.forEach(line => writeStream.write(line + '\n'));
});
```

## Reading Node.js Docs and Recap

Check official guides for detailed behavior: [Stream Handbook](https://github.com/substack/stream-handbook)

## Building Our Own Streaming Solution Using Buffers

Manual buffer management:

```js
const buffer = Buffer.from('Some large data here');
fs.writeFileSync('buffered.txt', buffer);
```

## Understanding Piping

```js
const fs = require('fs');
fs.createReadStream('input.txt').pipe(fs.createWriteStream('output.txt'));
```

## Implementing Our Own Writable Stream

```js
const { Writable } = require('stream');

class MyWritable extends Writable {
  _write(chunk, encoding, callback) {
    console.log(chunk.toString());
    callback();
  }
}

const writable = new MyWritable();
writable.write('Hello, custom stream!');
```

## Implementing Our Own Readable Stream

```js
const { Readable } = require('stream');

class MyReadable extends Readable {
  constructor() {
    super();
    this.index = 0;
  }
  _read() {
    if (this.index > 5) return this.push(null);
    this.push(`Chunk ${this.index++}\n`);
  }
}

const myStream = new MyReadable();
myStream.pipe(process.stdout);
```

## Understanding Duplex and Transform Streams

### Duplex Example:

```js
const { Duplex } = require('stream');

class Echo extends Duplex {
  _read(size) {}
  _write(chunk, encoding, callback) {
    this.push(chunk);
    callback();
  }
}

const echo = new Echo();
process.stdin.pipe(echo).pipe(process.stdout);
```

### Transform Example:

```js
const { Transform } = require('stream');

const upperCase = new Transform({
  transform(chunk, encoding, callback) {
    this.push(chunk.toString().toUpperCase());
    callback();
  }
});

process.stdin.pipe(upperCase).pipe(process.stdout);
```

---
